{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cats and dogs with linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import random, permutation\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((1,1,3))\n",
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean\n",
    "    return x[:, ::-1] # reverse axis rgb->bgr\n",
    "\n",
    "def ConvBlock(model, layers, filters):\n",
    "    for i in range(layers):\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Conv2D(filters, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "def FCBlock(model):\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "def BuildVGG():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(vgg_preprocess, input_shape=(224,224,3)))\n",
    "    ConvBlock(model, 2, 64)\n",
    "    ConvBlock(model, 2, 128)\n",
    "    ConvBlock(model, 3, 256)\n",
    "    ConvBlock(model, 3, 512)\n",
    "    ConvBlock(model, 3, 512)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    FCBlock(model)\n",
    "    FCBlock(model)\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    model.load_weights('/data/trained_models/vgg16_tf.h5')\n",
    "    model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BuildVGG()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build new model\n",
    "cd_model = BuildVGG()\n",
    "cd_model.pop()\n",
    "cd_model.pop()\n",
    "cd_model.pop()\n",
    "cd_model.pop()\n",
    "cd_model.pop()\n",
    "cd_model.add(Dense(4096, activation='relu'))\n",
    "cd_model.add(BatchNormalization())\n",
    "cd_model.add(Dropout(0.3))\n",
    "cd_model.add(Dense(4096, activation='relu'))\n",
    "cd_model.add(BatchNormalization())\n",
    "cd_model.add(Dropout(0.3))\n",
    "cd_model.add(Dense(3, activation='softmax'))\n",
    "cd_model.compile(optimizer=Adam(lr=0.00001),loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1333 images belonging to 3 classes.\n",
      "Found 148 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Images are of various sizes, but the smalest are 480x640\n",
    "\n",
    "train_batches_augmented = image.ImageDataGenerator(\n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    ").flow_from_directory(\n",
    "    '/data/cervical/raw_data/train', \n",
    "    target_size=(224,224),\n",
    "    class_mode='categorical', \n",
    "    shuffle=True, \n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "sample_valid_batches = image.ImageDataGenerator().flow_from_directory(\n",
    "    '/data/cervical/raw_data/valid', \n",
    "    target_size=(224,224),\n",
    "    class_mode='categorical', \n",
    "    shuffle=True, \n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cd_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9e64a84464e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m cd_model.fit_generator(train_batches_augmented, \n\u001b[0m\u001b[1;32m      2\u001b[0m                  \u001b[0mtrain_batches_augmented\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                  \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_valid_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m148\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cd_model' is not defined"
     ]
    }
   ],
   "source": [
    "cd_model.fit_generator(train_batches_augmented, \n",
    "                 samples_per_epoch=train_batches_augmented.samples,\n",
    "                 nb_epoch=1, \n",
    "                 validation_data=sample_valid_batches, \n",
    "                 nb_val_samples=sample_valid_batches.samples\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd_model.save_weights('/data/trained_models/dog_cat_complete_retrain_model_v1.0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches = image.ImageDataGenerator().flow_from_directory(\n",
    "    '/data/dogscats/test1', \n",
    "    target_size=(224,224),\n",
    "    class_mode=None, \n",
    "    shuffle=False, \n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches.filenames\n",
    "ids = np.array([int(f[8:f.find('.')]) for f in test_batches.filenames])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cd_model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(x):\n",
    "    if x < 0.0001:\n",
    "        return 0.0001\n",
    "    if x > 0.9999: \n",
    "        return 0.9999\n",
    "    return x\n",
    "\n",
    "cliped_data = [[ids[i], clip(results[i][1])] for i in range(ids.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[ids[i], 0.017 if results[i][1] < 0 else 0.983] for i in range(ids.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('/data/dogscats/test_result_rounded.csv', data ,fmt='%d,%.5f', header='id,label')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('/data/dogscats/test_sorted_result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating the restuls"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffled_valid_batches = image.ImageDataGenerator().flow_from_directory(\n",
    "    '/data/dogscats/my_photos', \n",
    "    target_size=(224,224),\n",
    "    class_mode='categorical', \n",
    "    shuffle=False, \n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, original_ids = next(suffled_valid_batches)\n",
    "dog_cat_result = cd_model.predict(imgs)\n",
    "dog_cat_label = np.vectorize(lambda x: ['cat','dog'][x])(np.argmax(dog_cat_result, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots(imgs, titles=dog_cat_label, rows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_batches = image.ImageDataGenerator().flow_from_directory(\n",
    "    '/data/dogscats/valid', \n",
    "    target_size=(224,224),\n",
    "    class_mode='categorical', \n",
    "    shuffle=False, \n",
    "    batch_size=32\n",
    ")\n",
    "valid_preds = cd_model.predict_generator(valid_batches, valid_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(valid_preds, axis=1)\n",
    "valid_labels = valid_batches.classes\n",
    "probs = valid_preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(preds,valid_labels)\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A few more examples\n",
    "\n",
    "It's a good idea to see where our model is most certain about it's decisions, and where it is relatively uncertain."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = image.ImageDataGenerator().flow_from_directory(\n",
    "    '/data/dogscats/valid', \n",
    "    target_size=(224,224),\n",
    "    class_mode='categorical', \n",
    "    shuffle=False, \n",
    ").filenames"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots_idx(idx, titles=None, rows=1, figsize=(12,6)):\n",
    "    plots([image.load_img('/data/dogscats/valid/' + filenames[i]) for i in idx], titles=titles, rows=rows, figsize=figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random correctly labelled"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.where(preds==valid_labels)[0]\n",
    "correct_idx = permutation(correct)[:8]\n",
    "plots_idx(correct_idx, titles=probs[correct_idx], rows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most confident about correct answer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_cats = np.where((preds==0) & (preds==valid_labels))[0]\n",
    "most_correct_cats = np.argsort(probs[correct_cats])[:8]\n",
    "plots_idx(correct_cats[most_correct_cats], probs[correct_cats][most_correct_cats], rows=2)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_dogs = np.where((preds==1) & (preds==valid_labels))[0]\n",
    "most_correct_dogs = np.argsort(probs[correct_dogs])[::-1][:8]\n",
    "plots_idx(correct_dogs[most_correct_dogs], probs[correct_dogs][most_correct_dogs], rows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All the wrong answers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_cats = np.where((preds==0) & (preds!=valid_labels))[0]\n",
    "most_incorrect_cats = np.argsort(probs[incorrect_cats])\n",
    "plots_idx(incorrect_cats[most_incorrect_cats], probs[incorrect_cats][most_incorrect_cats], rows=4,figsize=(14,12))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_dogs = np.where((preds==1) & (preds!=valid_labels))[0]\n",
    "most_incorrect_dogs = np.argsort(probs[incorrect_dogs])[::-1]\n",
    "plots_idx(incorrect_dogs[most_incorrect_dogs], probs[incorrect_dogs][most_incorrect_dogs],rows=4,figsize=(14,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most uncertain"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_uncertain = np.argsort(np.abs(probs-0.5))\n",
    "plots_idx(most_uncertain[:16], probs[most_uncertain], rows=4, figsize=(14,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the test set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = np.loadtxt('/data/dogscats/test_result_noclip.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "confident_dogs = test_results[test_results[:,1] > 0.9]\n",
    "confident_cats = test_results[test_results[:,1] < 0.1]\n",
    "most_uncertain = test_results[(test_results[:,1] > 0.4) & (test_results[:,1] < 0.6)]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "confident_cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_dogs = permutation(confident_dogs)[:16]\n",
    "random_cats = permutation(confident_cats)[:16]\n",
    "random_uncerain = permutation(most_uncertain)[:16]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots_test_by_idx(idx, titles=None, rows=1, figsize=(12,6)):\n",
    "    plots([image.load_img('/data/dogscats/test1/unknown/' + str(i) + '.jpg') for i in idx], titles=titles, rows=rows, figsize=figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Certain dogs"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_test_by_idx(random_dogs[:,0].astype(int), titles=random_dogs[:,1], rows=4, figsize=(14,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Certain cats"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_test_by_idx(random_cats[:,0].astype(int), titles=random_cats[:,1], rows=4, figsize=(14,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertain"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_test_by_idx(random_uncerain[:,0].astype(int), titles=random_uncerain[:,1], rows=4, figsize=(14,12))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}