{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 3647142\n"
     ]
    }
   ],
   "source": [
    "text = open('/data/orban/orban-complete', encoding='utf8').read()\n",
    "print('corpus length:', len(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 126\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n !%&'()+,-./0123456789:;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]abcdefghijklmnopqrstuvwxyz\\xa0§«\\xad»ÁÉÍÓÖÚÜàáäçèéíóöúüćčĐđĕğłńŐőşšűź̋–’“”„…\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars.insert(0, \"\\0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i+n] for i in range(0, len(idx)-1-cs, cs)] for n in range(cs)]\n",
    "c_out_dat = [[idx[i+n] for i in range(1, len(idx)-cs, cs)] for n in range(cs)]\n",
    "xs = [np.stack(c[:-2]) for c in c_in_dat]\n",
    "ys = [np.stack(c[:-2]) for c in c_out_dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1,  2,  2, ..., 75,  2, 67]),\n",
       " array([ 1,  2,  2, ..., 60, 68, 67]),\n",
       " array([ 2,  2,  2, ..., 73, 56, 62]),\n",
       " array([ 2,  2,  2, ..., 77, 65, 56]),\n",
       " array([ 2,  2,  2, ..., 60, 59, 75])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1,  2,  2, ...,  2, 56, 56]),\n",
       " array([ 1,  2,  2, ..., 75,  2, 67]),\n",
       " array([ 1,  2,  2, ..., 60, 68, 67]),\n",
       " array([ 2,  2,  2, ..., 73, 56, 62]),\n",
       " array([ 2,  2,  2, ..., 77, 65, 56])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rnn=np.stack(xs, axis=1)\n",
    "y_rnn=np.expand_dims(np.stack(ys, axis=1), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56984, 64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56984, 64, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rnn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, TimeDistributed, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from numpy.random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42 \n",
    "bs = 32\n",
    "n_hidden=512\n",
    "\n",
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, batch_input_shape=(bs,cs)),\n",
    "        BatchNormalization(),\n",
    "        LSTM(n_hidden, input_shape=(None,n_fac),return_sequences=True, dropout=0.2),\n",
    "        Dropout(0.2),\n",
    "        LSTM(n_hidden, return_sequences=True, dropout=0.2),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mx = len(x_rnn)//bs*bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "56960/56960 [==============================] - 419s - loss: 1.7859   \n",
      "Epoch 2/4\n",
      "56960/56960 [==============================] - 347s - loss: 1.3680   \n",
      "Epoch 3/4\n",
      "56960/56960 [==============================] - 349s - loss: 1.2900   \n",
      "Epoch 4/4\n",
      "56960/56960 [==============================] - 344s - loss: 1.2497   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f45b1213908>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn[:mx], y_rnn[:mx], batch_size=bs, epochs=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "56960/56960 [==============================] - 335s - loss: 1.1630   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f45aa6ba828>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn[:mx], y_rnn[:mx], batch_size=bs, epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=cs, batch_input_shape=(1,cs)),\n",
    "        BatchNormalization(),\n",
    "        LSTM(n_hidden, input_shape=(None,n_fac),return_sequences=True, dropout=0.2),\n",
    "        Dropout(0.2),\n",
    "        LSTM(n_hidden, return_sequences=True, dropout=0.2),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred_model.load_weights('/data/trained_models/nietzsche_lstm_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_example(seed_text, pred_model):\n",
    "    for c in range(1200):\n",
    "        last_chars = np.array([[char_indices[i] for i in list(seed_text[-cs:])]])\n",
    "        preds = pred_model.predict(last_chars)[0][-1]\n",
    "        preds = preds / np.sum(preds)\n",
    "        next_char = choice(chars, p=preds)\n",
    "        seed_text = seed_text + next_char\n",
    "    print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "Tisztelt          \n",
      "Jó nyomás előtt ez  a magyar gazdaságban, másodsorban konkrétumot képviselik, mert nem akarnak megállapítani, hogy valóban élünk föl az eljáró jogkormányzat óta érkeztek Görögország számára is. Az első területnek fizetjük a pulgária,  hogy a lapoktól dolgozó vállalat. Rendelkezésre emelkedhet az tőrük, hogy megemlítettük az Európai Unióért. A maga of pontja, hogy már mindig ezzel a fablárolta a politikát Schengeni Rezsicsökkentési Hárompolitikai stratégiának akarják láthatni. Ha az osztrák–magyar társadalom és világos iparűködésről keres a kormány, a másik fogadjon bennünket. Ezt még most köszönetet köszönettel fogalmazva, a következő időszakban az ehhez is döntést hirdessünk a polgári és a rendjét, hogy támogattunk együtt, amelyen határozott rákényességgel egy lehetővé teszi a vitá válságának élő határokat Európa javasolni. Ma már még a kormánynak vagy én idő lesz, meg kellene kellett befolyásolni. Mi, magyarok tetterősebb technológia rendszere  pedig ilyen a konkrét országnak, ahol ennek a pillanat miatt is a világ egy 500 évben létezjenek, Önök elfogadták, és elmondtam Önöket.\n",
      "\n",
      "Tisztelt Hölgyeim és Uraim!\n",
      "\n",
      "Négy országok pedig azért nem aztán sikerült magát közösen adot\n"
     ]
    }
   ],
   "source": [
    "print_example('                                                      \\nTisztelt ', pred_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nPREFACE\\n\\nDespite constant negative press- Covfefe'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'PREFACE\\n\\nDespite constant negative press- Covfefe'[:cs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_model.save_weights('/data/trained_models/nietzsche_lstm_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('                PREFACE\\n\\nDespite constant negative press Covfefe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
