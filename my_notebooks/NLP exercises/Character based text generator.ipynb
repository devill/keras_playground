{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "path = get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "text = open(path, encoding='utf8').read()\n",
    "print('corpus length:', len(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 85\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars.insert(0, \"\\0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i+n] for i in range(0, len(idx)-1-cs, cs)] for n in range(cs)]\n",
    "c_out_dat = [[idx[i+n] for i in range(1, len(idx)-cs, cs)] for n in range(cs)]\n",
    "xs = [np.stack(c[:-2]) for c in c_in_dat]\n",
    "ys = [np.stack(c[:-2]) for c in c_out_dat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([42, 73,  2, ..., 54, 54, 73]),\n",
       " array([29,  2, 61, ..., 67, 71, 58]),\n",
       " array([30, 60, 54, ...,  2, 57, 57]),\n",
       " array([25, 71, 75, ..., 72, 58,  9]),\n",
       " array([27, 68, 58, ..., 54, 57,  9])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([40, 68, 78, ..., 62, 60, 72]),\n",
       " array([42, 73,  2, ..., 54, 54, 73]),\n",
       " array([29,  2, 61, ..., 67, 71, 58]),\n",
       " array([30, 60, 54, ...,  2, 57, 57]),\n",
       " array([25, 71, 75, ..., 72, 58,  9])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_rnn=np.stack(xs, axis=1)\n",
    "y_rnn=np.expand_dims(np.stack(ys, axis=1), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, TimeDistributed, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from numpy.random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42 \n",
    "bs = 32\n",
    "n_hidden=512\n",
    "\n",
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, batch_input_shape=(bs,cs)),\n",
    "        BatchNormalization(),\n",
    "        LSTM(n_hidden, input_shape=(None,n_fac),return_sequences=True, dropout=0.2),\n",
    "        Dropout(0.2),\n",
    "        LSTM(n_hidden, return_sequences=True, dropout=0.2),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mx = len(x_rnn)//bs*bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/keras/models.py:849: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n",
      "/opt/conda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:2289: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "9376/9376 [==============================] - 129s - loss: 2.3775   \n",
      "Epoch 2/4\n",
      "9376/9376 [==============================] - 57s - loss: 1.8152    \n",
      "Epoch 3/4\n",
      "9376/9376 [==============================] - 57s - loss: 1.6437    \n",
      "Epoch 4/4\n",
      "9376/9376 [==============================] - 56s - loss: 1.5535    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb96b288e10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn[:mx], y_rnn[:mx], batch_size=bs, epochs=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "9376/9376 [==============================] - 55s - loss: 1.1396    \n",
      "Epoch 2/2\n",
      "9376/9376 [==============================] - 55s - loss: 1.1351    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb9287bb940>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn[:mx], y_rnn[:mx], batch_size=bs, epochs=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=cs, batch_input_shape=(1,cs)),\n",
    "        BatchNormalization(),\n",
    "        LSTM(n_hidden, input_shape=(None,n_fac),return_sequences=True, dropout=0.2),\n",
    "        Dropout(0.2),\n",
    "        LSTM(n_hidden, return_sequences=True, dropout=0.2),\n",
    "        Dropout(0.2),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_model.load_weights('/data/trained_models/nietzsche_lstm_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_example(seed_text, pred_model):\n",
    "    for c in range(1200):\n",
    "        last_chars = np.array([[char_indices[i] for i in list(seed_text[-cs:])]])\n",
    "        preds = pred_model.predict(last_chars)[0][-1]\n",
    "        preds = preds / np.sum(preds)\n",
    "        next_char = choice(chars, p=preds)\n",
    "        seed_text = seed_text + next_char\n",
    "    print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                PREFACE\n",
      "\n",
      "Despite constant negative press Covfefer or Possession.=--Has religion to its exercise sexual teppeatism and to these most menstom of the shadow and at\n",
      "pircumstances\n",
      "michtently recognized, and who no\n",
      "existence, that the\n",
      "animal in a lower closed contest, all preservation as the very upon one's own nature. Secondly to profoundly as well as in\n",
      "the general, great most echificeness and partly in the question here there are proad depends and\n",
      "unsufferend\n",
      "from it there is a morality of man and a deference is accused to it: wherever hand become a\n",
      "extent in intellect because of the best, this individual\n",
      "prevails and\n",
      "bravely be conceded deference through an\n",
      "allegorical ones (natural's historical estimates.\n",
      "\n",
      "\n",
      "199\n",
      "\n",
      "His Way soughly Said.=--The experience seems to immoral physiological\n",
      "shadows, more psychologically emphasized necessity. Although they, into\n",
      "the\n",
      "same and aim much to grateful for\n",
      "self-renunciation. This matter\n",
      "first in all absolutely\n",
      "wisdom\n",
      "that a bad is regarded to us to be bound to this\n",
      "constantly influence the child is restructed and our guided all them in the assertions of nature to defence is resulted preserved, to encluine the feeling with a colour soul: sensation, whether there can be greated by treats, however, h\n"
     ]
    }
   ],
   "source": [
    "print_example('                PREFACE\\n\\nDespite constant negative press Covfefe', pred_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nPREFACE\\n\\nDespite constant negative press- Covfefe'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'PREFACE\\n\\nDespite constant negative press- Covfefe'[:cs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_model.save_weights('/data/trained_models/nietzsche_lstm_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('                PREFACE\\n\\nDespite constant negative press Covfefe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
