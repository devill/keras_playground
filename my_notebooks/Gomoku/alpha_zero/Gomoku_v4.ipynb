{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython import display\n",
    "\n",
    "from gomoku import Gomoku\n",
    "from hand_crafted_gomoku_model import HandCraftedGomokuModel\n",
    "from monte_carlo_tree_search import MonteCarloTreeSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (19,19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example with decent hand crafted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Gomoku(shape)\n",
    "tree_search = MonteCarloTreeSearch(game, HandCraftedGomokuModel(), 2, 10)\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome: 1  Action: (8, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAD8CAYAAACLgjpEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f41533f0e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Over\n",
      "Outcome: 0.09347630396922774  Action: (9, 9)\n",
      "Outcome: -0.0  Action: (10, 8)\n",
      "Outcome: 0.11954281298598045  Action: (9, 7)\n",
      "Outcome: 0.03514177322837281  Action: (8, 8)\n",
      "Outcome: 0.2631886088105734  Action: (9, 8)\n",
      "Outcome: -0.02050493799078456  Action: (9, 10)\n",
      "Outcome: 0.15689635786822267  Action: (11, 7)\n",
      "Outcome: 0.029288495973527146  Action: (10, 10)\n",
      "Outcome: 0.23294830356431562  Action: (9, 5)\n",
      "Outcome: -0.11665398867074886  Action: (10, 7)\n",
      "Outcome: 0.3429411334713946  Action: (7, 5)\n",
      "Outcome: 0.0963795889995146  Action: (9, 6)\n",
      "Outcome: 0.13683162776087632  Action: (7, 6)\n",
      "Outcome: 0.35835739835078595  Action: (12, 5)\n",
      "Outcome: 0.21346299087202542  Action: (10, 6)\n",
      "Outcome: 0.24400045983060528  Action: (10, 9)\n",
      "Outcome: 0.35067302243502596  Action: (12, 8)\n",
      "Outcome: 0.04976354802793381  Action: (11, 8)\n",
      "Outcome: 1  Action: (8, 4)\n"
     ]
    }
   ],
   "source": [
    "game.draw() \n",
    "plt.show()\n",
    "for i in range(40):\n",
    "    if game.game_over():\n",
    "        print('Game Over')\n",
    "        break\n",
    "        \n",
    "    result = tree_search.search()\n",
    "    results.append(result)\n",
    "    game.take_action(result['action'])\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    print(\"Outcome: \" + str(result['outcome']) + \"  Action: \" + str(result['action']))\n",
    "    game.draw()    \n",
    "    plt.show()\n",
    "\n",
    "for r in results:\n",
    "    print(\"Outcome: \" + str(r['outcome']) + \"  Action: \" + str(r['action']))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_count = 512\n",
    "\n",
    "input_state= Input(shape=(shape[0],shape[1],3))\n",
    "x = Conv2D(hidden_layer_count, (7,7), padding='same', activation='relu')(input_state)\n",
    "x = Conv2D(hidden_layer_count, (5,5), padding='same', activation='relu')(x)\n",
    "x = Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization(axis=3)(x)\n",
    "x = Conv2D(hidden_layer_count, (7,7), padding='same', activation='relu')(x)\n",
    "x = Conv2D(hidden_layer_count, (5,5), padding='same', activation='relu')(x)\n",
    "x = Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization(axis=3)(x)\n",
    "\n",
    "pmx = Conv2D(hidden_layer_count, (10,10), padding='same', activation='relu')(x)\n",
    "pmx = Conv2D(hidden_layer_count, (10,10), padding='same', activation='relu')(pmx)\n",
    "pmx = Conv2D(1, (1,1), padding='same', activation='relu')(pmx)\n",
    "pmx = Flatten()(pmx)\n",
    "prob_map = Activation('softmax', name='prob_map')(pmx)\n",
    "\n",
    "wx = Conv2D(hidden_layer_count, (10,10), padding='valid', activation='relu')(x)\n",
    "wx = Conv2D(hidden_layer_count, (10,10), padding='valid', activation='relu')(wx)\n",
    "wx = GlobalMaxPooling2D()(wx)\n",
    "winner = Dense(1, activation='tanh', name='winner')(wx)\n",
    "\n",
    "model = Model(input_state, [prob_map, winner])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Nadam(), \n",
    "    loss=['categorical_crossentropy', 'mean_squared_error'],\n",
    "    loss_weights=[1, shape[0]*shape[1]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train with hand crafted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_to_onehot(action):\n",
    "    result = np.zeros(shape)\n",
    "    result[action] = 1\n",
    "    return result\n",
    "\n",
    "def board_augmentation(inp, out):\n",
    "    sym = random.choice([' ','|','\\\\'])\n",
    "    if sym == '|':\n",
    "        inp = np.flip(inp,axis=0)\n",
    "        out = np.flip(out,axis=0)\n",
    "    elif sym =='\\\\':\n",
    "        inp = np.transpose(inp, axes=(1,0,2))\n",
    "        out = np.transpose(out)\n",
    "\n",
    "    k = random.randint(0,3)\n",
    "    return np.rot90(inp,k=k, axes=(0,1)), np.rot90(out,k=k, axes=(0,1))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Gomoku(shape)\n",
    "tree_search = MonteCarloTreeSearch(game, HandCraftedGomokuModel(), 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "for batch_index in range(1):\n",
    "    batch_input = []\n",
    "    batch_move_pred = []\n",
    "    batch_win_pred = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        if game.game_over():\n",
    "            game.reset()\n",
    "\n",
    "        result = tree_search.search()\n",
    "\n",
    "        board, action = board_augmentation(game.get_state_for_current_player(), action_to_onehot(result['action']))\n",
    "        \n",
    "        batch_input.append(board)\n",
    "        batch_move_pred.append(action.flatten())\n",
    "        batch_win_pred.append(result['outcome'])\n",
    "\n",
    "        game.take_action(result['action'])\n",
    "\n",
    "        #display.clear_output(wait=True)\n",
    "        #print(str(i) + \" Outcome: \" + str(result['outcome']) + \"  Action: \" + str(result['action']))\n",
    "        #game.draw()    \n",
    "        #plt.show()\n",
    "\n",
    "    losses = model.train_on_batch(np.array(batch_input), [np.array(batch_move_pred), np.array(batch_win_pred)])\n",
    "    print(batch_index, losses, end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train from recorded games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/data/gomoku_alpha_zero'\n",
    "data_files = [f for f in listdir(data_path) if isfile(join(data_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_boards = []\n",
    "train_scores = []\n",
    "train_actions = []\n",
    "\n",
    "for file in data_files:\n",
    "    with open(data_path+\"/\"+file, 'r') as f:\n",
    "        board = np.stack((np.zeros(shape), np.zeros(shape),np.ones(shape)), axis=2)\n",
    "        player = 0\n",
    "        for line in f.readlines():\n",
    "            line = line.split(',')\n",
    "            \n",
    "            original = np.copy(board)\n",
    "            action = action_to_onehot((int(line[1]), int(line[2])))\n",
    "            \n",
    "            original, action = board_augmentation(original, action)\n",
    "            \n",
    "            train_boards.append(original)\n",
    "            train_scores.append(float(line[0]))\n",
    "            train_actions.append(action.flatten())\n",
    "            \n",
    "            board[int(line[1]), int(line[2]), player] = 1\n",
    "            player = 1 - player\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21419"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "21419/21419 [==============================] - 250s 12ms/step - loss: 278.8121 - prob_map_loss: 5.8889 - winner_loss: 0.7560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40cc444080>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(train_boards), [np.array(train_actions),np.array(train_scores)], shuffle=True, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reenforment learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choice2d(pmap, count = 10):\n",
    "    shape = pmap.shape\n",
    "    indices = np.transpose(np.indices(shape), axes=(1,2,0)).reshape((shape[0]*shape[1],2))\n",
    "    choice_indices = np.random.choice(len(indices), count, p=pmap.reshape(shape[0]*shape[1]))\n",
    "    return list(map(lambda x: tuple(x), indices[choice_indices].tolist()))\n",
    "\n",
    "class LearnedGomokuModel:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def predicted_outcome(self, game):\n",
    "        pred = model.predict(np.array([game.get_state_for_current_player()]))\n",
    "        return pred[1][0][0]\n",
    "\n",
    "    def most_probable_actions(self, game, max_branching):\n",
    "        return list(set(choice2d(self.get_probability_map(game), max_branching)))\n",
    "    \n",
    "    def get_probability_map(self, game):\n",
    "        pred = model.predict(np.array([game.get_state_for_current_player()]))\n",
    "        pmap = np.multiply(pred[0][0].reshape(game.get_shape()), 1-game.get_occupied())\n",
    "        return pmap / np.sum(pmap) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Gomoku(shape)\n",
    "lmodel = LearnedGomokuModel(model)\n",
    "tree_search = MonteCarloTreeSearch(game, LearnedGomokuModel(model), 2, 10)\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome: -1/1.0  Action: (2, 7)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAD8CAYAAACLgjpEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f40bc213940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAD8CAYAAACLgjpEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f40bc25a588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-66576b929dd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/my_notebooks/Gomoku/alpha_zero/monte_carlo_tree_search.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mnew_outcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'outcome'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_outcome\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'outcome'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/my_notebooks/Gomoku/alpha_zero/monte_carlo_tree_search.py\u001b[0m in \u001b[0;36m__get_outcome\u001b[0;34m(self, depth, alpha, beta)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwinner_from_last_players_perspective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__search_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/src/my_notebooks/Gomoku/alpha_zero/monte_carlo_tree_search.py\u001b[0m in \u001b[0;36m__search_outcome\u001b[0;34m(self, depth, alpha, beta)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mnew_outcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_outcome\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/my_notebooks/Gomoku/alpha_zero/monte_carlo_tree_search.py\u001b[0m in \u001b[0;36m__get_outcome\u001b[0;34m(self, depth, alpha, beta)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwinner_from_last_players_perspective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__search_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/src/my_notebooks/Gomoku/alpha_zero/monte_carlo_tree_search.py\u001b[0m in \u001b[0;36m__search_outcome\u001b[0;34m(self, depth, alpha, beta)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mnew_outcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_outcome\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/my_notebooks/Gomoku/alpha_zero/monte_carlo_tree_search.py\u001b[0m in \u001b[0;36m__get_outcome\u001b[0;34m(self, depth, alpha, beta)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwinner_from_last_players_perspective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__search_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/src/my_notebooks/Gomoku/alpha_zero/monte_carlo_tree_search.py\u001b[0m in \u001b[0;36m__search_outcome\u001b[0;34m(self, depth, alpha, beta)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__search_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0moutcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-613d1890d602>\u001b[0m in \u001b[0;36mpredicted_outcome\u001b[0;34m(self, game)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredicted_outcome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state_for_current_player\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1790\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1300\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "game.draw() \n",
    "plt.show()\n",
    "for i in range(40):\n",
    "    if game.game_over():\n",
    "        print('Game Over')\n",
    "        break\n",
    "        \n",
    "    result = tree_search.search()\n",
    "    results.append(result)\n",
    "    game.take_action(result['action'])\n",
    "    predicted_outcome = lmodel.predicted_outcome(game)\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    print(\"Outcome: \" + str(result['outcome']) + \"/\" + str(predicted_outcome) + \"  Action: \" + str(result['action']))\n",
    "    game.draw()    \n",
    "    plt.show()\n",
    "    plt.imshow(lmodel.get_probability_map(game))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "for r in results:\n",
    "    print(\"Outcome: \" + str(r['outcome']) + \"  Action: \" + str(r['action']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lmodel = LearnedGomokuModel(model)\n",
    "lmodel = HandCraftedGomokuModel()\n",
    "print(lmodel.predicted_outcome(game))\n",
    "plt.imshow(lmodel.get_probability_map(game))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('/data/gomoku_alpha_zero/v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
