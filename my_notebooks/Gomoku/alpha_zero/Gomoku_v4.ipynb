{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython import display\n",
    "\n",
    "from gomoku import Gomoku\n",
    "from gomoku_with_group_map import GomokuWithGroupMap\n",
    "from hand_crafted_gomoku_model import HandCraftedGomokuModel\n",
    "from monte_carlo_tree_search import MonteCarloTreeSearch\n",
    "from parallel_monte_carlo_tree_search import ParallelMonteCarloTreeSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (19,19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example with decent hand crafted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = GomokuWithGroupMap(shape)\n",
    "tree_search = MonteCarloTreeSearch(game, HandCraftedGomokuModel(), 2, 10)\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome: 1  Action: (11, 11)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAD8CAYAAACLgjpEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1GRASGoyICQ1/S8cAa66RGh23gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3cad9ecf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Over\n",
      "Outcome: 0.005039957325745597  Action: (9, 9)\n",
      "Outcome: 0.0017999980560025224  Action: (10, 8)\n",
      "Outcome: 0.005849933267038512  Action: (7, 7)\n",
      "Outcome: 0.00989967657967936  Action: (7, 8)\n",
      "Outcome: 0.034995703089282036  Action: (8, 8)\n",
      "Outcome: -0.012419361417906121  Action: (8, 7)\n",
      "Outcome: 0.2192232513667264  Action: (10, 10)\n",
      "Outcome: -0.18373938881917315  Action: (9, 6)\n",
      "Outcome: 0.20288540386961826  Action: (7, 9)\n",
      "Outcome: -0.1647156241449967  Action: (9, 7)\n",
      "Outcome: 0.21527865742408853  Action: (8, 9)\n",
      "Outcome: -0.024924836577914063  Action: (10, 5)\n",
      "Outcome: 1  Action: (11, 11)\n"
     ]
    }
   ],
   "source": [
    "game.draw() \n",
    "plt.show()\n",
    "for i in range(100):\n",
    "    if game.game_over():\n",
    "        print('Game Over')\n",
    "        break\n",
    "        \n",
    "    result = tree_search.search()\n",
    "    results.append(result)\n",
    "    game.take_action(result['action'])\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    print(\"Outcome: \" + str(result['outcome']) + \"  Action: \" + str(result['action']))\n",
    "    game.draw()    \n",
    "    plt.show()\n",
    "\n",
    "for r in results:\n",
    "    print(\"Outcome: \" + str(r['outcome']) + \"  Action: \" + str(r['action']))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Activation, LeakyReLU, add\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block(width,inp):\n",
    "    x = Conv2D(width, (3,3), padding='same')(inp)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = Conv2D(width, (3,3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = Conv2D(width, (3,3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = add([x, inp])\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    return BatchNormalization(axis=3)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_pooling_block(width,inp):\n",
    "    x = Conv2D(width, (3,3), padding='same')(inp)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(2*width, (3,3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(4*width, (3,3), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_count = 512\n",
    "\n",
    "input_state= Input(shape=(shape[0],shape[1],3))\n",
    "x = Conv2D(hidden_layer_count, (7,7), padding='same', activation='relu')(input_state)\n",
    "x = res_block(hidden_layer_count, x)\n",
    "x = res_block(hidden_layer_count, x)\n",
    "x = res_block(hidden_layer_count, x)\n",
    "\n",
    "pmx = res_block(hidden_layer_count, x)\n",
    "pmx = Conv2D(1, (1,1), padding='same')(pmx)\n",
    "pmx = LeakyReLU(alpha=0.3)(pmx)\n",
    "pmx = Flatten()(pmx)\n",
    "prob_map = Activation('softmax', name='prob_map')(pmx)\n",
    "\n",
    "#wx = down_pooling_block(hidden_layer_count, x)\n",
    "wx = res_block(hidden_layer_count, x)\n",
    "wx = GlobalAveragePooling2D()(wx)\n",
    "wx = Dense(hidden_layer_count)(wx)\n",
    "wx = LeakyReLU(alpha=0.3)(wx)\n",
    "winner = Dense(1, activation='tanh', name='winner')(wx)\n",
    "\n",
    "\n",
    "model = Model(input_state, [prob_map,winner])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Nadam(), \n",
    "    loss=['categorical_crossentropy','mean_squared_error'],\n",
    "    loss_weights=[1, 2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/data/trained_models/gomoku_alpha_zero_resnet_weights_v4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train with hand crafted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_to_onehot(action):\n",
    "    result = np.zeros(shape)\n",
    "    result[action] = 1\n",
    "    return result\n",
    "\n",
    "def board_augmentation(inp, out):\n",
    "    sym = random.choice([' ','|','\\\\'])\n",
    "    if sym == '|':\n",
    "        inp = np.flip(inp,axis=0)\n",
    "        out = np.flip(out,axis=0)\n",
    "    elif sym =='\\\\':\n",
    "        inp = np.transpose(inp, axes=(1,0,2))\n",
    "        out = np.transpose(out)\n",
    "\n",
    "    k = random.randint(0,3)\n",
    "    return np.rot90(inp,k=k, axes=(0,1)), np.rot90(out,k=k, axes=(0,1))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = GomokuWithGroupMap(shape)\n",
    "tree_search = MonteCarloTreeSearch(game, HandCraftedGomokuModel(), 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "for batch_index in range(0):\n",
    "    batch_input = []\n",
    "    batch_move_pred = []\n",
    "    batch_win_pred = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        if game.game_over():\n",
    "            game.reset()\n",
    "\n",
    "        result = tree_search.search()\n",
    "\n",
    "        board, action = board_augmentation(game.get_state_for_current_player(), action_to_onehot(result['action']))\n",
    "        \n",
    "        batch_input.append(board)\n",
    "        batch_move_pred.append(action.flatten())\n",
    "        batch_win_pred.append(result['outcome'])\n",
    "\n",
    "        game.take_action(result['action'])\n",
    "\n",
    "        #display.clear_output(wait=True)\n",
    "        #print(str(i) + \" Outcome: \" + str(result['outcome']) + \"  Action: \" + str(result['action']))\n",
    "        #game.draw()    \n",
    "        #plt.show()\n",
    "\n",
    "    losses = model.train_on_batch(np.array(batch_input), [np.array(batch_move_pred), np.array(batch_win_pred)])\n",
    "    print(batch_index, losses, end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre train from recorded games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/data/gomoku_alpha_zero/2_10'\n",
    "data_files = [f for f in listdir(data_path) if isfile(join(data_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_boards = []\n",
    "train_scores = []\n",
    "train_actions = []\n",
    "\n",
    "base = np.ones(shape)\n",
    "base[game.get_middle()] += 1\n",
    "\n",
    "for file in data_files:\n",
    "    with open(data_path+\"/\"+file, 'r') as f:\n",
    "        board = np.stack((np.zeros(shape), np.zeros(shape),np.copy(base)), axis=2)\n",
    "        player = 0\n",
    "        for line in f.readlines():\n",
    "            line = line.split(',')\n",
    "            \n",
    "            original = np.copy(board)\n",
    "            action = action_to_onehot((int(line[1]), int(line[2])))\n",
    "            \n",
    "            original, action = board_augmentation(original, action)\n",
    "            \n",
    "            train_boards.append(original)\n",
    "            train_scores.append(float(line[0]))\n",
    "            train_actions.append(action.flatten())\n",
    "            \n",
    "            board[int(line[1]), int(line[2]), player] = 1\n",
    "            player = 1 - player\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(np.array(train_boards), [np.array(train_actions),np.array(train_scores)], shuffle=True, epochs=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('/data/trained_models/gomoku_alpha_zero_resnet_full_model_v4_1.h5')\n",
    "#model.save_weights('/data/trained_models/gomoku_alpha_zero_resnet_weights_v4_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reenforment learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choice2d(pmap, count = 10):\n",
    "    shape = pmap.shape\n",
    "    indices = np.transpose(np.indices(shape), axes=(1,2,0)).reshape((shape[0]*shape[1],2))\n",
    "    choice_indices = np.random.choice(len(indices), count, p=pmap.reshape(shape[0]*shape[1]))\n",
    "    return list(map(lambda x: tuple(x), indices[choice_indices].tolist()))\n",
    "\n",
    "class LearnedGomokuModel:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def get_predicted_outcomes(self, boards):\n",
    "        pred = model.predict(boards)\n",
    "        return pred[1].flatten()\n",
    "    \n",
    "    def get_probability_maps(self, boards):\n",
    "        pred = model.predict(boards)\n",
    "        shape = (boards.shape[0], boards.shape[1], boards.shape[2])\n",
    "        return pred[0].reshape(shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Gomoku(shape)\n",
    "lmodel = LearnedGomokuModel(model)\n",
    "tree_search = ParallelMonteCarloTreeSearch(LearnedGomokuModel(model), 3, 3)\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome: 1/0.637812  Action: (3, 8)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAD8CAYAAACLgjpEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3c67ca0d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-691c76cb3052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0moutcomes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'outcome'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moutcomes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'action'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpredicted_outcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_predicted_outcomes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state_for_current_player\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/my_notebooks/Gomoku/alpha_zero/parallel_monte_carlo_tree_search.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, games)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__search_outcomes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__search_outcomes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/my_notebooks/Gomoku/alpha_zero/parallel_monte_carlo_tree_search.py\u001b[0m in \u001b[0;36m__search_outcomes\u001b[0;34m(self, games, depth)\u001b[0m\n\u001b[1;32m     66\u001b[0m                     \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'range_to'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_games\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0moutcomes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__search_outcomes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_games\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mbest_outcomes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/my_notebooks/Gomoku/alpha_zero/parallel_monte_carlo_tree_search.py\u001b[0m in \u001b[0;36m__search_outcomes\u001b[0;34m(self, games, depth)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mmaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_probability_maps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mnext_games\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-102-e653f796ace5>\u001b[0m in \u001b[0;36mget_probability_maps\u001b[0;34m(self, boards)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_probability_maps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mboards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1790\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1300\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while not game.game_over():\n",
    "    outcomes, actions = tree_search.search([game])\n",
    "    results.append({'outcome':outcomes[0], 'action':actions[0]})\n",
    "    game.take_action(actions[0])\n",
    "    predicted_outcome = lmodel.get_predicted_outcomes(np.array([game.get_state_for_current_player()]))\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    print(\"Outcome: \" + str(outcomes[0]) + \"/\" + str(predicted_outcome[0]) + \"  Action: \" + str(actions[0]))\n",
    "    pmap = lmodel.get_probability_maps(np.array([game.get_state_for_current_player()]))\n",
    "    board = game.get_state()\n",
    "    plt.imshow(np.stack([board[:,:,0], board[:,:,1], pmap[0]/np.max(pmap[0])], axis = 2))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "for r in results:\n",
    "    print(\"Outcome: \" + str(r['outcome']) + \"  Action: \" + str(r['action']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmodel = LearnedGomokuModel(model)\n",
    "#lmodel = HandCraftedGomokuModel()\n",
    "print(lmodel.predicted_outcome(game))\n",
    "plt.imshow(lmodel.get_probability_map(game))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
