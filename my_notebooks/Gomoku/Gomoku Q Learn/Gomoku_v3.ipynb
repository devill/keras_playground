{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape = (19,19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement game logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Gomoku:\n",
    "    \n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.last_player = 1\n",
    "        self.board = np.stack((np.zeros(self.shape), np.zeros(self.shape),np.ones(self.shape)), axis=2)\n",
    "        self.previous_board = np.copy(self.board)\n",
    "    \n",
    "    def draw(self):\n",
    "        plt.imshow(self.board)\n",
    "    \n",
    "    def list_actions(self):\n",
    "        return np.transpose(np.nonzero(self.board[:,:,2])).tolist()\n",
    "        \n",
    "    def take_action(self, action):\n",
    "        self.previous_board = np.copy(self.board)\n",
    "        self.last_player = 1 - self.last_player \n",
    "        pixel = np.zeros((3))\n",
    "        pixel[self.last_player] = 1\n",
    "        self.board[action] = pixel\n",
    "        self.last_action = action\n",
    "        return self.__revard()\n",
    "    \n",
    "    def get_last_action(self):\n",
    "        return self.last_action\n",
    "    \n",
    "    def get_state(self):\n",
    "        return self.convert_state_for_player(self.board, self.last_player)\n",
    "    \n",
    "    def get_raw_state(self):\n",
    "        return self.board\n",
    "    \n",
    "    def get_previous_state(self):\n",
    "        return self.convert_state_for_player(self.previous_board, self.last_player)\n",
    "    \n",
    "    def convert_state_for_player(self, board, player):\n",
    "        result = np.copy(board)\n",
    "        \n",
    "        if player == 1:\n",
    "            tmp = np.copy(result[:,:,0])\n",
    "            result[:,:,0] = result[:,:,1]\n",
    "            result[:,:,1] = tmp\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def game_over(self):\n",
    "        return self.__won(0) or self.__won(1) or np.count_nonzero(self.board[:,:,2]) == 0\n",
    "    \n",
    "    def __revard(self):\n",
    "        return 1 if self.__won(self.last_player) else 0\n",
    "        \n",
    "    def __won(self, player):\n",
    "        board = self.board[:,:, player]\n",
    "        return (\n",
    "            self.__has_five_by(np.identity(5), board) or \n",
    "            self.__has_five_by(np.fliplr(np.identity(5)), board) or \n",
    "            self.__has_five_by(np.ones((1,5)), board) or \n",
    "            self.__has_five_by(np.ones((5,1)), board)\n",
    "        )\n",
    "    \n",
    "    def __has_five_by(self, mask, board):\n",
    "        return np.count_nonzero(signal.convolve2d(mask, board) == 5) > 0\n",
    "    \n",
    "game = Gomoku(shape)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deep Q learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_layer_count = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_state = Input(shape=game.get_state().shape)\n",
    "x = Conv2D(hidden_layer_count, (7,7), padding='same', activation='relu')(input_state)\n",
    "x = Conv2D(hidden_layer_count, (5,5), padding='same', activation='relu')(x)\n",
    "x = Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization(axis=3)(x)\n",
    "x = Conv2D(hidden_layer_count, (7,7), padding='same', activation='relu')(x)\n",
    "x = Conv2D(hidden_layer_count, (5,5), padding='same', activation='relu')(x)\n",
    "x = Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization(axis=3)(x)\n",
    "prob_map = Conv2D(1, (1,1), padding='same', activation='relu')(x)\n",
    "winner = GlobalMaxPooling2D()(prob_map)\n",
    "\n",
    "model = Model(input_state, winner)\n",
    "map_model = Model(input_state, prob_map)\n",
    "\n",
    "opt = Nadam(lr=1e-5)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy')\n",
    "map_model.compile(optimizer=opt, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_move():\n",
    "    if game.game_over():\n",
    "        return\n",
    "    \n",
    "    if np.random.rand() < epsilon:\n",
    "        action = tuple(random.choice(game.list_actions()))\n",
    "    else: \n",
    "        q = model.predict(np.expand_dims(game.get_state(), axis=0)).reshape(shape)\n",
    "        action = tuple(sorted(game.list_actions(), key=lambda x: q[tuple(x)])[-1])\n",
    "        \n",
    "    return make_manual_move(action)\n",
    "\n",
    "def make_manual_move(action):\n",
    "    if game.game_over():\n",
    "        return\n",
    "    \n",
    "    revard = game.take_action(action)\n",
    "    return [game.get_previous_state(), action, revard, game.get_state(), game.game_over()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07759527,  0.04737442,  0.11939137,  0.08218905,  0.17152865,\n",
       "         0.08011203,  0.04622764,  0.20202038,  0.07601954,  0.05204586,\n",
       "         0.1211382 ,  0.0833847 ,  0.06910384,  0.11528851,  0.1069544 ,\n",
       "         0.08209111,  0.11662121,  0.11993162,  0.06925429,  0.05142764,\n",
       "         0.08038506,  0.10802316,  0.08072764,  0.09815552,  0.09605538,\n",
       "         0.14821672,  0.1114252 ,  0.10503768,  0.08283931,  0.12878175,\n",
       "         0.05962959,  0.04498002,  0.11816934,  0.12710357,  0.07555363,\n",
       "         0.12029865,  0.02097337,  0.14544865,  0.02945024,  0.12941884]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.expand_dims(game.get_state(), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 14440 into shape (19,19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d9eb5fb66613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcolor_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 14440 into shape (19,19)"
     ]
    }
   ],
   "source": [
    "color_map = map_model.predict(np.expand_dims(game.get_state(), axis=0)).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<div id='display_div'></div>\n",
       "<button onclick='next()'>Make Next AI Move</button>\n",
       "<button onclick='play()'>Autoplay</button>\n",
       "<button onclick='reset()'>New Game</button>\n",
       "\n",
       "<script type=\"text/Javascript\">\n",
       "\n",
       "    function display_state(out) {\n",
       "        document.getElementById('display_div').innerHTML = out.content.text;\n",
       "    }\n",
       "\n",
       "    function next() {\n",
       "        var kernel = IPython.notebook.kernel;\n",
       "        kernel.execute('make_move()');\n",
       "        kernel.execute('state_for_display()', {\"iopub\" : {\"output\":display_state}});\n",
       "    }\n",
       "    \n",
       "    function make_move(i,j) {\n",
       "        var kernel = IPython.notebook.kernel;\n",
       "        kernel.execute('make_manual_move(('+i+', '+j+'))');\n",
       "        kernel.execute('state_for_display()', {\"iopub\" : {\"output\":display_state}});\n",
       "        setTimeout(next, 300);\n",
       "    }\n",
       "    \n",
       "    function play() {\n",
       "        var kernel = IPython.notebook.kernel;\n",
       "        next();\n",
       "        kernel.execute('print(game.game_over(), end=\"\")', {\"iopub\" : {\"output\":function(out) {\n",
       "            if(out.content.text == \"False\") {\n",
       "                setTimeout(play, 100);\n",
       "            }\n",
       "        }}});\n",
       "        \n",
       "    }\n",
       "    \n",
       "    function reset() {\n",
       "        var kernel = IPython.notebook.kernel;\n",
       "        kernel.execute('game.reset()');\n",
       "        next()\n",
       "    }\n",
       "    \n",
       "    next()\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display as core_display\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "def state_for_display():\n",
    "    raw_state = game.get_raw_state()\n",
    "    last_action = game.get_last_action()\n",
    "    color_map = model.predict(np.expand_dims(game.get_state(), axis=0)).reshape(shape)\n",
    "    color_map = color_map - np.min(color_map)\n",
    "    color_map = (color_map / np.max(color_map) * 255).astype(int)\n",
    "    \n",
    "    html = '<table>'\n",
    "    for i in range(shape[0]):\n",
    "        html += '<tr>'\n",
    "        for j in range(shape[1]):\n",
    "                        \n",
    "            html += \"<td style='border:1px solid gray; width:25px; height:25px; fotn-weight:bold; text-align:center; \"\n",
    "            if last_action == (i,j): \n",
    "                html += \"background-color:rgb(255, \"+str(color_map[i,j])+\", \"+str(255-color_map[i,j])+\");\" \n",
    "            else: \n",
    "                html += \"background-color:rgb(0, \"+ str(color_map[i,j]) +\", \"+str(255-color_map[i,j])+\");\" \n",
    "                \n",
    "            html += \"'\"\n",
    "            if raw_state[i,j,2]:\n",
    "                html += \" onclick='make_move(\"+str(i)+\",\"+str(j)+\")'\"\n",
    "            html += \">\"\n",
    "            if raw_state[i,j,0] == 1:\n",
    "                html += 'X'\n",
    "            if raw_state[i,j,1] == 1:\n",
    "                html += 'O'\n",
    "            if raw_state[i,j,0] == 1:\n",
    "                html += '&nbsp;'                \n",
    "                \n",
    "            html += \"</td>\"\n",
    "        html += '</tr>'\n",
    "\n",
    "    html += '</table>'\n",
    "    if game.game_over():\n",
    "        html += '<h3>Game Over</h3>'\n",
    "    print(html)\n",
    "\n",
    "game.reset()\n",
    "\n",
    "\n",
    "\n",
    "html = \"\"\"\n",
    "\n",
    "<div id='display_div'></div>\n",
    "<button onclick='next()'>Make Next AI Move</button>\n",
    "<button onclick='play()'>Autoplay</button>\n",
    "<button onclick='reset()'>New Game</button>\n",
    "\n",
    "<script type=\"text/Javascript\">\n",
    "\n",
    "    function display_state(out) {\n",
    "        document.getElementById('display_div').innerHTML = out.content.text;\n",
    "    }\n",
    "\n",
    "    function next() {\n",
    "        var kernel = IPython.notebook.kernel;\n",
    "        kernel.execute('make_move()');\n",
    "        kernel.execute('state_for_display()', {\"iopub\" : {\"output\":display_state}});\n",
    "    }\n",
    "    \n",
    "    function make_move(i,j) {\n",
    "        var kernel = IPython.notebook.kernel;\n",
    "        kernel.execute('make_manual_move(('+i+', '+j+'))');\n",
    "        kernel.execute('state_for_display()', {\"iopub\" : {\"output\":display_state}});\n",
    "        setTimeout(next, 300);\n",
    "    }\n",
    "    \n",
    "    function play() {\n",
    "        var kernel = IPython.notebook.kernel;\n",
    "        next();\n",
    "        kernel.execute('print(game.game_over(), end=\"\")', {\"iopub\" : {\"output\":function(out) {\n",
    "            if(out.content.text == \"False\") {\n",
    "                setTimeout(play, 100);\n",
    "            }\n",
    "        }}});\n",
    "        \n",
    "    }\n",
    "    \n",
    "    function reset() {\n",
    "        var kernel = IPython.notebook.kernel;\n",
    "        kernel.execute('game.reset()');\n",
    "        next()\n",
    "    }\n",
    "    \n",
    "    next()\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "core_display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading real games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "experiences = []\n",
    "wins = []\n",
    "\n",
    "def letter_to_index(letter):\n",
    "    if(ord(letter) < ord('J')):\n",
    "        return ord(letter)-65\n",
    "    else:\n",
    "        return ord(letter)-66\n",
    "\n",
    "def game_log_to_tuples(log):\n",
    "    return list(map(lambda l: (letter_to_index(l[0]),int(l[1:-1])-1),log))\n",
    "\n",
    "files = os.listdir('/data/bsd_gomoku_games')\n",
    "\n",
    "skipped_files = 0\n",
    "\n",
    "for filename in tqdm(files):\n",
    "    if filename[-4:] == '.log':\n",
    "        with open('/data/bsd_gomoku_games/'+filename) as f:\n",
    "            content = game_log_to_tuples(f.readlines())\n",
    "\n",
    "        if len(content) < 200:\n",
    "            game.reset()\n",
    "            for move in content:\n",
    "                make_manual_move(move)\n",
    "        else:\n",
    "            skipped_files += 1\n",
    "\n",
    "print(skipped_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount = 0.9\n",
    "\n",
    "for k in tqdm(range(1000)):\n",
    "    seed_batch = random.sample(experiences,len(wins)) + wins\n",
    "\n",
    "    original_q = model.predict(np.array([item[0] for item in seed_batch]))\n",
    "\n",
    "    revards = np.array([item[2] for item in seed_batch])\n",
    "    game_over = np.array([item[4] for item in seed_batch]).astype(int)\n",
    "\n",
    "    desired_q = np.zeros(original_q.shape)\n",
    "    for index in range(len(desired_q)):\n",
    "        desired_q[index][seed_batch[index][1]] = revards[index]\n",
    "\n",
    "    loss = model.train_on_batch(np.array([item[0] for item in seed_batch]), desired_q)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discount = 0.9\n",
    "\n",
    "for k in tqdm(range(1000)):\n",
    "    if k % 300:\n",
    "        opt.lr = opt.lr/10\n",
    "        \n",
    "    seed_batch = random.sample(experiences, min(2000,len(experiences)))\n",
    "\n",
    "    original_q = model.predict(np.array([item[0] for item in seed_batch]))\n",
    "    new_q = model.predict(np.array([item[3] for item in seed_batch]))\n",
    "\n",
    "    new_q_max = np.squeeze(np.max(np.max(new_q, axis=1), axis=1), axis=1)\n",
    "\n",
    "    revards = np.array([item[2] for item in seed_batch])\n",
    "    game_over = np.array([item[4] for item in seed_batch]).astype(int)\n",
    "    calculated_q = (revards + discount * new_q_max * (1-game_over)).tolist()\n",
    "\n",
    "    desired_q = np.copy(original_q)\n",
    "    for index in range(len(calculated_q)):\n",
    "        desired_q[index][seed_batch[index][1]] = calculated_q[index]\n",
    "\n",
    "    loss = model.train_on_batch(np.array([item[0] for item in seed_batch]), desired_q)\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    print(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "protect_until = len(experiences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "protect_until"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt.lr = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discount = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(12000)):\n",
    "    game.reset()\n",
    "    game_length = 0\n",
    "    while not game.game_over():\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = tuple(random.choice(game.list_actions()))\n",
    "        else: \n",
    "            q = model.predict(np.expand_dims(game.get_state(), axis=0)).reshape(shape)\n",
    "            action = tuple(sorted(game.list_actions(), key=lambda x: q[tuple(x)])[-1])\n",
    "\n",
    "        revard = game.take_action(action)\n",
    "\n",
    "        experiences.append([game.get_previous_state(), action, revard, game.get_state(), game.game_over()])\n",
    "        game_length+=1\n",
    "\n",
    "    experiences[-2][2] = -1\n",
    "    \n",
    "    for k in range(3):\n",
    "        seed_batch = random.sample(experiences[:protect_until], min(1000,protect_until)) + random.sample(experiences[protect_until:], min(1000,len(experiences)-protect_until))\n",
    "\n",
    "        original_q = model.predict(np.array([item[0] for item in seed_batch]))\n",
    "        new_q_max = training_model.predict(np.array([item[3] for item in seed_batch]))\n",
    "\n",
    "        revards = np.array([item[2] for item in seed_batch])\n",
    "        calculated_q = revards + discount * np.squeeze(new_q_max)\n",
    "\n",
    "        loss = training_model.train_on_batch(np.array([item[0] for item in seed_batch]), calculated_q)\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    print(i, game_length, loss, '(', len(experiences), ')')\n",
    "    \n",
    "    if len(experiences) > 100000:\n",
    "        experiences = experiences[:protect_until] + random.sample(experiences[protect_until:], 50000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
