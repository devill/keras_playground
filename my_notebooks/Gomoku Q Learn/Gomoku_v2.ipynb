{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape = (9,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement game logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Gomoku:\n",
    "    \n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.last_player = 1\n",
    "        self.board = np.stack((np.zeros(self.shape), np.zeros(self.shape),np.ones(self.shape)), axis=2)\n",
    "        self.previous_board = np.copy(self.board)\n",
    "    \n",
    "    def draw(self):\n",
    "        plt.imshow(self.board)\n",
    "    \n",
    "    def list_actions(self):\n",
    "        return np.transpose(np.nonzero(self.board[:,:,2])).tolist()\n",
    "        \n",
    "    def take_action(self, action):\n",
    "        self.previous_board = np.copy(self.board)\n",
    "        self.last_player = 1 - self.last_player \n",
    "        pixel = np.zeros((3))\n",
    "        pixel[self.last_player] = 1\n",
    "        self.board[action] = pixel\n",
    "        self.last_action = action\n",
    "        return self.__revard()\n",
    "    \n",
    "    def get_last_action(self):\n",
    "        return self.last_action\n",
    "    \n",
    "    def get_state(self):\n",
    "        return self.convert_state_for_player(self.board, self.last_player)\n",
    "    \n",
    "    def get_raw_state(self):\n",
    "        return self.board\n",
    "    \n",
    "    def get_previous_state(self):\n",
    "        return self.convert_state_for_player(self.previous_board, self.last_player)\n",
    "    \n",
    "    def convert_state_for_player(self, board, player):\n",
    "        result = np.copy(board)\n",
    "        \n",
    "        if player == 1:\n",
    "            tmp = np.copy(result[:,:,0])\n",
    "            result[:,:,0] = result[:,:,1]\n",
    "            result[:,:,1] = tmp\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def game_over(self):\n",
    "        return self.__won(0) or self.__won(1) or np.count_nonzero(self.board[:,:,2]) == 0\n",
    "    \n",
    "    def __revard(self):\n",
    "        return 1 if self.__won(self.last_player) else 0\n",
    "        \n",
    "    def __won(self, player):\n",
    "        board = self.board[:,:, player]\n",
    "        return (\n",
    "            self.__has_five_by(np.identity(5), board) or \n",
    "            self.__has_five_by(np.fliplr(np.identity(5)), board) or \n",
    "            self.__has_five_by(np.ones((1,5)), board) or \n",
    "            self.__has_five_by(np.ones((5,1)), board)\n",
    "        )\n",
    "    \n",
    "    def __has_five_by(self, mask, board):\n",
    "        return np.count_nonzero(signal.convolve2d(mask, board) == 5) > 0\n",
    "    \n",
    "game = Gomoku(shape)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deep Q learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_layer_count = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_state = Input(shape=game.get_state().shape)\n",
    "x = Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu')(input_state)\n",
    "x = Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu')(x)\n",
    "x = Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization(axis=3)(x)\n",
    "x = Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu')(x)\n",
    "x = Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu')(x)\n",
    "x = Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization(axis=3)(x)\n",
    "x = Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu')(x)\n",
    "x = Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu')(x)\n",
    "x = Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization(axis=3)(x)\n",
    "q_out = Conv2D(1, (3,3), padding='same')(x)\n",
    "q_max = GlobalMaxPooling2D()(q_out)\n",
    "\n",
    "model = Model(input_state, q_out)\n",
    "training_model = Model(input_state, q_max)\n",
    "\n",
    "opt = Nadam(lr=1e-5)\n",
    "model.compile(optimizer=opt, loss='mean_squared_error')\n",
    "training_model.compile(optimizer=opt, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_move():\n",
    "    if game.game_over():\n",
    "        return\n",
    "    \n",
    "    if np.random.rand() < epsilon:\n",
    "        action = tuple(random.choice(game.list_actions()))\n",
    "    else: \n",
    "        q = model.predict(np.expand_dims(game.get_state(), axis=0)).reshape(shape)\n",
    "        action = tuple(sorted(game.list_actions(), key=lambda x: q[tuple(x)])[-1])\n",
    "        \n",
    "    revard = game.take_action(action)\n",
    "    experiences.append([game.get_previous_state(), action, revard, game.get_state(), game.game_over()])\n",
    "\n",
    "def make_manual_move(i, j):\n",
    "    if game.game_over():\n",
    "        return\n",
    "    \n",
    "    game.take_action((i,j))\n",
    "    experiences.append([game.get_previous_state(), action, revard, game.get_state(), game.game_over()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_map = model.predict(np.expand_dims(game.get_state(), axis=0)).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4d8feac160>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+x9hHVW4hBwHgAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4d94f438d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(color_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<div id='display_div'></div>\n",
       "<button onclick='next()'>Make Next AI Move</button>\n",
       "<button onclick='play()'>Autoplay</button>\n",
       "<button onclick='reset()'>New Game</button>\n",
       "\n",
       "<script type=\"text/Javascript\">\n",
       "\n",
       "    function display_state(out) {\n",
       "        document.getElementById('display_div').innerHTML = out.content.text;\n",
       "    }\n",
       "\n",
       "    function next() {\n",
       "        var kernel = IPython.notebook.kernel;\n",
       "        kernel.execute('make_move()');\n",
       "        kernel.execute('state_for_display()', {\"iopub\" : {\"output\":display_state}});\n",
       "    }\n",
       "    \n",
       "    function make_move(i,j) {\n",
       "        var kernel = IPython.notebook.kernel;\n",
       "        kernel.execute('make_manual_move('+i+', '+j+')');\n",
       "        kernel.execute('state_for_display()', {\"iopub\" : {\"output\":display_state}});\n",
       "        setTimeout(next, 300);\n",
       "    }\n",
       "    \n",
       "    function play() {\n",
       "        var kernel = IPython.notebook.kernel;\n",
       "        next();\n",
       "        kernel.execute('print(game.game_over(), end=\"\")', {\"iopub\" : {\"output\":function(out) {\n",
       "            if(out.content.text == \"False\") {\n",
       "                setTimeout(play, 100);\n",
       "            }\n",
       "        }}});\n",
       "        \n",
       "    }\n",
       "    \n",
       "    function reset() {\n",
       "        var kernel = IPython.notebook.kernel;\n",
       "        kernel.execute('game.reset()');\n",
       "        next()\n",
       "    }\n",
       "    \n",
       "    next()\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display as core_display\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "def state_for_display():\n",
    "    raw_state = game.get_raw_state()\n",
    "    last_action = game.get_last_action()\n",
    "    color_map = model.predict(np.expand_dims(game.get_state(), axis=0)).reshape(shape)\n",
    "    color_map = color_map - np.min(color_map)\n",
    "    color_map = (color_map / np.max(color_map) * 255).astype(int)\n",
    "    \n",
    "    html = '<table>'\n",
    "    for i in range(shape[0]):\n",
    "        html += '<tr>'\n",
    "        for j in range(shape[1]):\n",
    "                        \n",
    "            html += \"<td style='border:1px solid gray; width:25px; height:25px; fotn-weight:bold; text-align:center; \"\n",
    "            if last_action == (i,j): \n",
    "                html += \"background-color:rgb(255, \"+str(color_map[i,j])+\", \"+str(255-color_map[i,j])+\");\" \n",
    "            else: \n",
    "                html += \"background-color:rgb(0, \"+ str(color_map[i,j]) +\", \"+str(255-color_map[i,j])+\");\" \n",
    "                \n",
    "            html += \"'\"\n",
    "            if raw_state[i,j,2]:\n",
    "                html += \" onclick='make_move(\"+str(i)+\",\"+str(j)+\")'\"\n",
    "            html += \">\"\n",
    "            if raw_state[i,j,0] == 1:\n",
    "                html += 'X'\n",
    "            if raw_state[i,j,1] == 1:\n",
    "                html += 'O'\n",
    "            if raw_state[i,j,0] == 1:\n",
    "                html += '&nbsp;'                \n",
    "                \n",
    "            html += \"</td>\"\n",
    "        html += '</tr>'\n",
    "\n",
    "    html += '</table>'\n",
    "    if game.game_over():\n",
    "        html += '<h3>Game Over</h3>'\n",
    "    print(html)\n",
    "\n",
    "game.reset()\n",
    "\n",
    "\n",
    "\n",
    "html = \"\"\"\n",
    "\n",
    "<div id='display_div'></div>\n",
    "<button onclick='next()'>Make Next AI Move</button>\n",
    "<button onclick='play()'>Autoplay</button>\n",
    "<button onclick='reset()'>New Game</button>\n",
    "\n",
    "<script type=\"text/Javascript\">\n",
    "\n",
    "    function display_state(out) {\n",
    "        document.getElementById('display_div').innerHTML = out.content.text;\n",
    "    }\n",
    "\n",
    "    function next() {\n",
    "        var kernel = IPython.notebook.kernel;\n",
    "        kernel.execute('make_move()');\n",
    "        kernel.execute('state_for_display()', {\"iopub\" : {\"output\":display_state}});\n",
    "    }\n",
    "    \n",
    "    function make_move(i,j) {\n",
    "        var kernel = IPython.notebook.kernel;\n",
    "        kernel.execute('make_manual_move('+i+', '+j+')');\n",
    "        kernel.execute('state_for_display()', {\"iopub\" : {\"output\":display_state}});\n",
    "        setTimeout(next, 300);\n",
    "    }\n",
    "    \n",
    "    function play() {\n",
    "        var kernel = IPython.notebook.kernel;\n",
    "        next();\n",
    "        kernel.execute('print(game.game_over(), end=\"\")', {\"iopub\" : {\"output\":function(out) {\n",
    "            if(out.content.text == \"False\") {\n",
    "                setTimeout(play, 100);\n",
    "            }\n",
    "        }}});\n",
    "        \n",
    "    }\n",
    "    \n",
    "    function reset() {\n",
    "        var kernel = IPython.notebook.kernel;\n",
    "        kernel.execute('game.reset()');\n",
    "        next()\n",
    "    }\n",
    "    \n",
    "    next()\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "core_display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt.lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discount = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501 49 0.0578765 ( 28406 )\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e8af1ad7dfbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moriginal_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseed_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mnew_q_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseed_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mrevards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseed_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1592\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1594\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1216\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1218\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1219\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    game.reset()\n",
    "    game_length = 0\n",
    "    while not game.game_over():\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = tuple(random.choice(game.list_actions()))\n",
    "        else: \n",
    "            q = model.predict(np.expand_dims(game.get_state(), axis=0)).reshape(shape)\n",
    "            action = tuple(sorted(game.list_actions(), key=lambda x: q[tuple(x)])[-1])\n",
    "\n",
    "        revard = game.take_action(action)\n",
    "\n",
    "        experiences.append([game.get_previous_state(), action, revard, game.get_state(), game.game_over()])\n",
    "        game_length+=1\n",
    "\n",
    "    experiences[-2][2] = -1\n",
    "    \n",
    "    for k in range(3):\n",
    "        seed_batch = random.sample(experiences, min(2000,len(experiences)))\n",
    "\n",
    "        original_q = model.predict(np.array([item[0] for item in seed_batch]))\n",
    "        new_q_max = training_model.predict(np.array([item[3] for item in seed_batch]))\n",
    "\n",
    "        revards = np.array([item[2] for item in seed_batch])\n",
    "        calculated_q = revards + discount * np.squeeze(new_q_max)\n",
    "\n",
    "        loss = training_model.train_on_batch(np.array([item[0] for item in seed_batch]), calculated_q)\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    print(i, game_length, loss, '(', len(experiences), ')')\n",
    "    \n",
    "    if len(experiences) > 30000:\n",
    "        experiences = random.sample(experiences, 25000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
