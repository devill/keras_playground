{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape = (13,13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement game logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Gomoku:\n",
    "    \n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.last_player = 1\n",
    "        self.board = np.stack((np.zeros(self.shape), np.zeros(self.shape),np.ones(self.shape)), axis=2)\n",
    "        self.previous_board = np.copy(self.board)\n",
    "    \n",
    "    def draw(self):\n",
    "        plt.imshow(self.board)\n",
    "    \n",
    "    def list_actions(self):\n",
    "        return np.transpose(np.nonzero(self.board[:,:,2])).tolist()\n",
    "        \n",
    "    def take_action(self, action):\n",
    "        self.previous_board = np.copy(self.board)\n",
    "        self.last_player = 1 - self.last_player \n",
    "        pixel = np.zeros((3))\n",
    "        pixel[self.last_player] = 1\n",
    "        self.board[action] = pixel\n",
    "        self.last_action = action\n",
    "        return self.__revard()\n",
    "    \n",
    "    def get_last_action(self):\n",
    "        return self.last_action\n",
    "    \n",
    "    def get_state(self):\n",
    "        return self.convert_state_for_player(self.board, self.last_player)\n",
    "    \n",
    "    def get_raw_state(self):\n",
    "        return self.board\n",
    "    \n",
    "    def get_previous_state(self):\n",
    "        return self.convert_state_for_player(self.previous_board, self.last_player)\n",
    "    \n",
    "    def convert_state_for_player(self, board, player):\n",
    "        result = np.copy(board)\n",
    "        \n",
    "        if player == 1:\n",
    "            result[:,:,[0,1]] = result[:,:,[1,0]]\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def game_over(self):\n",
    "        return self.__won(0) or self.__won(1) or np.count_nonzero(self.board[:,:,2]) == 0\n",
    "    \n",
    "    def __revard(self):\n",
    "        return 1 if self.__won(self.last_player) else 0\n",
    "        \n",
    "    def __won(self, player):\n",
    "        board = self.board[:,:, player]\n",
    "        return (\n",
    "            self.__has_five_by(np.identity(5), board) or \n",
    "            self.__has_five_by(np.fliplr(np.identity(5)), board) or \n",
    "            self.__has_five_by(np.ones((1,5)), board) or \n",
    "            self.__has_five_by(np.ones((5,1)), board)\n",
    "        )\n",
    "    \n",
    "    def __has_five_by(self, mask, board):\n",
    "        return np.count_nonzero(signal.convolve2d(mask, board) == 5) > 0\n",
    "    \n",
    "game = Gomoku(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deep Q learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_layer_count = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu', input_shape=game.get_state().shape),\n",
    "    Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(axis=3),\n",
    "    Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(axis=3),\n",
    "    Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(hidden_layer_count, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(axis=3),\n",
    "    Conv2D(1, (3,3), padding='same')\n",
    "])\n",
    "\n",
    "opt = Nadam(lr=1e-5)\n",
    "model.compile(optimizer=opt, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('/data/trained_models/gomoku_q_learn/initial_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon = 0.01\n",
    "delta = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_move():\n",
    "    if game.game_over():\n",
    "        return\n",
    "    \n",
    "    if np.random.rand() < epsilon:\n",
    "        action = tuple(random.choice(game.list_actions()))\n",
    "    else: \n",
    "        q = model.predict(np.expand_dims(game.get_state(), axis=0)).reshape(shape)\n",
    "\n",
    "        prefered_moves = sorted(game.list_actions(), key=lambda x: -q[tuple(x)])\n",
    "        \n",
    "        i = 0\n",
    "        while np.random.rand() < delta and i < len(prefered_moves)-1:\n",
    "            i += 1\n",
    "\n",
    "        action = tuple(prefered_moves[i])\n",
    "\n",
    "    revard = game.take_action(action)\n",
    "\n",
    "    experiences.append([game.get_previous_state(), action, revard, game.get_state(), game.game_over()])\n",
    "\n",
    "def make_manual_move(i, j):\n",
    "    if game.game_over():\n",
    "        return\n",
    "    \n",
    "    game.take_action((i,j))\n",
    "    experiences.append([game.get_previous_state(), action, revard, game.get_state(), game.game_over()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<div id='display_div'></div>\n",
       "<button onclick='next()'>Make Next AI Move</button>\n",
       "<button onclick='play()'>Autoplay</button>\n",
       "<button onclick='reset()'>New Game</button>\n",
       "\n",
       "<script type=\"text/Javascript\">\n",
       "\n",
       "    function display_state(out) {\n",
       "        document.getElementById('display_div').innerHTML = out.content.text;\n",
       "    }\n",
       "\n",
       "    function next() {\n",
       "        var kernel = IPython.notebook.kernel;\n",
       "        kernel.execute('make_move()');\n",
       "        kernel.execute('state_for_display()', {\"iopub\" : {\"output\":display_state}});\n",
       "    }\n",
       "    \n",
       "    function make_move(i,j) {\n",
       "        var kernel = IPython.notebook.kernel;\n",
       "        kernel.execute('make_manual_move('+i+', '+j+')');\n",
       "        kernel.execute('state_for_display()', {\"iopub\" : {\"output\":display_state}});\n",
       "        setTimeout(next, 300);\n",
       "    }\n",
       "    \n",
       "    function play() {\n",
       "        var kernel = IPython.notebook.kernel;\n",
       "        next();\n",
       "        kernel.execute('print(game.game_over(), end=\"\")', {\"iopub\" : {\"output\":function(out) {\n",
       "            if(out.content.text == \"False\") {\n",
       "                setTimeout(play, 100);\n",
       "            }\n",
       "        }}});\n",
       "        \n",
       "    }\n",
       "    \n",
       "    function reset() {\n",
       "        var kernel = IPython.notebook.kernel;\n",
       "        kernel.execute('game.reset()');\n",
       "        next()\n",
       "    }\n",
       "    \n",
       "    next()\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display as core_display\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "def state_for_display():\n",
    "    raw_state = game.get_raw_state()\n",
    "    last_action = game.get_last_action()\n",
    "    color_map = model.predict(np.expand_dims(game.get_state(), axis=0)).reshape(shape)\n",
    "    color_map = color_map - np.min(color_map)\n",
    "    color_map = (color_map / np.max(color_map) * 255).astype(int)\n",
    "    \n",
    "    html = '<table>'\n",
    "    for i in range(shape[0]):\n",
    "        html += '<tr>'\n",
    "        for j in range(shape[1]):\n",
    "                        \n",
    "            html += \"<td style='border:1px solid gray; width:25px; height:25px; fotn-weight:bold; text-align:center; \"\n",
    "            if last_action == (i,j): \n",
    "                html += \"background-color:rgb(255, \"+str(color_map[i,j])+\", \"+str(255-color_map[i,j])+\");\" \n",
    "            else: \n",
    "                html += \"background-color:rgb(0, \"+ str(color_map[i,j]) +\", \"+str(255-color_map[i,j])+\");\" \n",
    "                \n",
    "            html += \"'\"\n",
    "            if raw_state[i,j,2]:\n",
    "                html += \" onclick='make_move(\"+str(i)+\",\"+str(j)+\")'\"\n",
    "            html += \">\"\n",
    "            if raw_state[i,j,0] == 1:\n",
    "                html += 'X'\n",
    "            if raw_state[i,j,1] == 1:\n",
    "                html += 'O'\n",
    "            if raw_state[i,j,0] == 1:\n",
    "                html += '&nbsp;'                \n",
    "                \n",
    "            html += \"</td>\"\n",
    "        html += '</tr>'\n",
    "\n",
    "    html += '</table>'\n",
    "    if game.game_over():\n",
    "        html += '<h3>Game Over</h3>'\n",
    "    print(html)\n",
    "\n",
    "game.reset()\n",
    "\n",
    "\n",
    "\n",
    "html = \"\"\"\n",
    "\n",
    "<div id='display_div'></div>\n",
    "<button onclick='next()'>Make Next AI Move</button>\n",
    "<button onclick='play()'>Autoplay</button>\n",
    "<button onclick='reset()'>New Game</button>\n",
    "\n",
    "<script type=\"text/Javascript\">\n",
    "\n",
    "    function display_state(out) {\n",
    "        document.getElementById('display_div').innerHTML = out.content.text;\n",
    "    }\n",
    "\n",
    "    function next() {\n",
    "        var kernel = IPython.notebook.kernel;\n",
    "        kernel.execute('make_move()');\n",
    "        kernel.execute('state_for_display()', {\"iopub\" : {\"output\":display_state}});\n",
    "    }\n",
    "    \n",
    "    function make_move(i,j) {\n",
    "        var kernel = IPython.notebook.kernel;\n",
    "        kernel.execute('make_manual_move('+i+', '+j+')');\n",
    "        kernel.execute('state_for_display()', {\"iopub\" : {\"output\":display_state}});\n",
    "        setTimeout(next, 300);\n",
    "    }\n",
    "    \n",
    "    function play() {\n",
    "        var kernel = IPython.notebook.kernel;\n",
    "        next();\n",
    "        kernel.execute('print(game.game_over(), end=\"\")', {\"iopub\" : {\"output\":function(out) {\n",
    "            if(out.content.text == \"False\") {\n",
    "                setTimeout(play, 100);\n",
    "            }\n",
    "        }}});\n",
    "        \n",
    "    }\n",
    "    \n",
    "    function reset() {\n",
    "        var kernel = IPython.notebook.kernel;\n",
    "        kernel.execute('game.reset()');\n",
    "        next()\n",
    "    }\n",
    "    \n",
    "    next()\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "core_display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon = 0.2\n",
    "delta = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt.lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discount = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 39 0.00742505 ( 2825 )\n",
      "."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-caab57277a91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0mnext_valid_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_counter_moves\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mnew_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_valid_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mnew_q_max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1592\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1594\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1216\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1218\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1219\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n\u001b[1;32m    917\u001b[0m                          'graph before calling run().')\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    game.reset()\n",
    "    game_length = 0\n",
    "    while not game.game_over():\n",
    "        make_move()\n",
    "        game_length+=1\n",
    "\n",
    "    experiences[-2][2] = -1\n",
    "    \n",
    "    for k in range(5):\n",
    "        print('.', end='')\n",
    "        seed_batch = random.sample(experiences, min(100,len(experiences)))\n",
    "\n",
    "        original_q = model.predict(np.array([item[0] for item in seed_batch]))\n",
    "        \n",
    "        new_q_max = []\n",
    "        for index in range(len(seed_batch)):\n",
    "            valid_counter_moves = np.transpose(np.nonzero(seed_batch[index][3][:,:,2])).tolist()\n",
    "\n",
    "            next_valid_states = list(map(lambda m: np.copy(seed_batch[index][3]), valid_counter_moves))\n",
    "            \n",
    "            if len(next_valid_states) > 0:\n",
    "                for state_index in range(len(valid_counter_moves)):\n",
    "                    next_valid_states[state_index][tuple(valid_counter_moves[state_index])] = np.array([0,1,0])\n",
    "\n",
    "                new_q = np.array(model.predict(np.array(next_valid_states)))\n",
    "\n",
    "                new_q_max.append(np.min(np.max(np.max(new_q, axis=1), axis=1), axis=0)[0])\n",
    "            else:\n",
    "                new_q_max.append(0)\n",
    "        \n",
    "        revards = np.array([item[2] for item in seed_batch])\n",
    "        game_over = np.array([item[4] for item in seed_batch]).astype(int)\n",
    "        calculated_q = (revards + discount * np.array(new_q_max) * (1-game_over)).tolist()\n",
    "\n",
    "        desired_q = np.copy(original_q)\n",
    "        for index in range(len(calculated_q)):\n",
    "            desired_q[index][seed_batch[index][1]] = calculated_q[index]\n",
    "\n",
    "        loss = model.train_on_batch(np.array([item[0] for item in seed_batch]), desired_q)\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    print(i, game_length, loss, '(', len(experiences), ')')\n",
    "    \n",
    "    if len(experiences) > 30000:\n",
    "        experiences = random.sample(experiences, 25000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[55, 31, 49, 38, 68, 58, 33, 63, 6, 78]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(range(100), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
