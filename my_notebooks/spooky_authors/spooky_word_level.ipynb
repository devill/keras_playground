{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load glove vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bcolz\n",
    "import re\n",
    "from numpy.random import normal\n",
    "import _pickle as pickle\n",
    "\n",
    "def load_vectors(loc):\n",
    "    return (load_array(loc+'.dat'),\n",
    "        pickle.load(open(loc+'_words.pkl','rb')),\n",
    "        pickle.load(open(loc+'_idx.pkl','rb')))\n",
    "\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vecs, glove_words, glove_wordidx = load_vectors('/data/glove/results/6B.300d')\n",
    "glove_vec_len = len(glove_vecs[0])\n",
    "glove_vecs = np.append(glove_vecs, np.zeros((1,glove_vec_len)), axis=0)\n",
    "glove_words.append('####')\n",
    "glove_wordidx['####'] = len(glove_words) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "raw_train_data = []\n",
    "raw_train_labels = []\n",
    "\n",
    "with open('/data/spooky_author/train_ascii.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    for lid, text, author in reader:\n",
    "        raw_train_data.append(text)\n",
    "        raw_train_labels.append(author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and transform training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenized_train_data = list(map(lambda x: word_tokenize(x.lower()), raw_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19579/19579 [00:00<00:00, 54289.98it/s]\n"
     ]
    }
   ],
   "source": [
    "wordid_train_data = []\n",
    "\n",
    "for sentence in tqdm(tokenized_train_data):\n",
    "    wordid_train_data.append([])\n",
    "    for word in sentence: \n",
    "        if word in glove_wordidx:\n",
    "            wordid_train_data[-1].append(glove_wordidx[word])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emptyidx = glove_wordidx['####']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_lens = list(map(lambda x: len(x), wordid_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVDmDXpIqZ9BLUuUMekmq3P8DS2H51fvvZwUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbf176e42e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = plt.hist(line_lens, bins=100, range=(0, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = np.array([(([emptyidx]*max_len) + text)[-max_len:] for text in wordid_train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([400000, 400000, 400000, 400000, 400000, 400000, 400000, 400000,\n",
       "       400000, 400000, 400000, 400000, 400000, 400000, 400000, 400000,\n",
       "       400000, 400000, 400000, 400000, 400000, 400000, 400000, 400000,\n",
       "       400000, 400000, 400000, 400000, 400000, 400000, 400000, 400000,\n",
       "       400000, 400000, 400000, 400000, 400000, 400000, 400000, 400000,\n",
       "       400000, 400000, 400000, 400000, 400000, 400000, 400000, 400000,\n",
       "       400000, 400000, 400000, 400000, 400000, 400000, 400000, 400000,\n",
       "       400000, 400000, 400000, 400000, 400000, 400000, 400000, 400000,\n",
       "       400000,     20,    332,    442,   1858,      4,    285,     12,\n",
       "            0,  43888,    414,     30,      7,   6575,   3895,      2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400001, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfrom labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = sorted(list(set(raw_train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_indices = dict((a, i) for i, a in enumerate(authors))\n",
    "indices_autor = dict((i, a) for i, a in enumerate(authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlabels = to_categorical(list(map(lambda l: author_indices[l], raw_train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data to train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, valid_data, train_labels, valid_labels  = train_test_split(tdata, tlabels, test_size=0.05, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18600, 80) (979, 80) (18600, 3) (979, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, valid_data.shape, train_labels.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(glove_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, GRU, Dense, Dropout, TimeDistributed,Bidirectional, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "n_fac = 512 \n",
    "bs = 612\n",
    "n_hidden=512\n",
    "\n",
    "model=Sequential([\n",
    "        Embedding(vocab_size, glove_vec_len, batch_input_shape=(None,max_len),weights=[glove_vecs], trainable=False),\n",
    "        BatchNormalization(),\n",
    "        Bidirectional(GRU(n_hidden,input_shape=(None,n_fac),return_sequences=True)),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        #GRU(n_hidden, dropout=0.3, recurrent_dropout=0.1, return_sequences=True),\n",
    "        #GRU(n_hidden, dropout=0.3, recurrent_dropout=0.1),\n",
    "        Dense(1024, activation='relu'),\n",
    "        Dropout(0.9),\n",
    "        Dense(number_of_classes, activation='softmax')\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Nadam()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_23 to have 3 dimensions, but got array with shape (18600, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-7bae5fadfe75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlystop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1581\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1582\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1416\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1419\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1420\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_23 to have 3 dimensions, but got array with shape (18600, 3)"
     ]
    }
   ],
   "source": [
    "model.fit(train_data, train_labels, validation_data=(valid_data, valid_labels), batch_size=bs, epochs=100,callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds = model.predict(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.]\n",
      "[ 0.83295828  0.12181897  0.04522278]\n",
      "at each end of its axis this screw is supported by pillars of hollow brass tube descending from the hoop .\n"
     ]
    }
   ],
   "source": [
    "idx = 5\n",
    "print(valid_labels[idx])\n",
    "print(valid_preds[idx])\n",
    "print(' '.join([w for w in map(lambda x: glove_words[x], valid_data[idx]) if w != '####']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nevermore = np.zeros((1,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nevermore[0,0] = glove_wordidx['nevermore']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4963308 ,  0.31137946,  0.19228974]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(nevermore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_data[0]\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
