{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load glove vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bcolz\n",
    "import re\n",
    "from numpy.random import normal\n",
    "import _pickle as pickle\n",
    "\n",
    "def load_vectors(loc):\n",
    "    return (load_array(loc+'.dat'),\n",
    "        pickle.load(open(loc+'_words.pkl','rb')),\n",
    "        pickle.load(open(loc+'_idx.pkl','rb')))\n",
    "\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vecs, glove_words, glove_wordidx = load_vectors('/data/glove/results/6B.300d')\n",
    "glove_vec_len = len(glove_vecs[0])\n",
    "glove_vecs = np.append(glove_vecs, np.zeros((1,glove_vec_len)), axis=0)\n",
    "glove_words.append('####')\n",
    "glove_wordidx['####'] = len(glove_words) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "raw_train_data = []\n",
    "raw_train_labels = []\n",
    "\n",
    "with open('/data/spooky_author/train_ascii.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    for lid, text, author in reader:\n",
    "        raw_train_data.append(text)\n",
    "        raw_train_labels.append(author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and transform training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenized_train_data = list(map(lambda x: word_tokenize(x.lower()), raw_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19579/19579 [00:00<00:00, 62727.89it/s]\n"
     ]
    }
   ],
   "source": [
    "wordid_train_data = []\n",
    "\n",
    "for sentence in tqdm(tokenized_train_data):\n",
    "    wordid_train_data.append([])\n",
    "    for word in sentence: \n",
    "        if word in glove_wordidx:\n",
    "            wordid_train_data[-1].append(glove_wordidx[word])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emptyidx = glove_wordidx['####']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_lens = list(map(lambda x: len(x), wordid_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVDmDXpIqZ9BLUuUMekmq3P8DS2H51fvvZwUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1fc639beb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = plt.hist(line_lens, bins=100, range=(0, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = np.array([(([emptyidx]*max_len) + text)[-max_len:] for text in wordid_train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([400000, 400000, 400000, 400000, 400000,     20,    332,    442,\n",
       "         1858,      4,    285,     12,      0,  43888,    414,     30,\n",
       "            7,   6575,   3895,      2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400001, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfrom labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = sorted(list(set(raw_train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_indices = dict((a, i) for i, a in enumerate(authors))\n",
    "indices_autor = dict((i, a) for i, a in enumerate(authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlabels = to_categorical(list(map(lambda l: author_indices[l], raw_train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data to train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, valid_data, train_labels, valid_labels  = train_test_split(tdata, tlabels, test_size=0.05, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18600, 20) (979, 20) (18600, 3) (979, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, valid_data.shape, train_labels.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(glove_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[400001,300]\n\t [[Node: embedding_13/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_13/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_13/embeddings, embedding_13/random_uniform)]]\n\nCaused by op 'embedding_13/embeddings/Assign', defined at:\n  File \"/opt/conda/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/conda/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/conda/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-79-1111ffef4862>\", line 18, in <module>\n    Dense(number_of_classes, activation='softmax')\n  File \"/opt/conda/lib/python3.5/site-packages/keras/models.py\", line 408, in __init__\n    self.add(layer)\n  File \"/opt/conda/lib/python3.5/site-packages/keras/models.py\", line 464, in add\n    layer(x)\n  File \"/opt/conda/lib/python3.5/site-packages/keras/engine/topology.py\", line 576, in __call__\n    self.build(input_shapes[0])\n  File \"/opt/conda/lib/python3.5/site-packages/keras/layers/embeddings.py\", line 101, in build\n    dtype=self.dtype)\n  File \"/opt/conda/lib/python3.5/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/keras/engine/topology.py\", line 400, in add_weight\n    constraint=constraint)\n  File \"/opt/conda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 385, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 346, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 57, in assign\n    use_locking=use_locking, name=name)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[400001,300]\n\t [[Node: embedding_13/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_13/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_13/embeddings, embedding_13/random_uniform)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[400001,300]\n\t [[Node: embedding_13/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_13/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_13/embeddings, embedding_13/random_uniform)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-1111ffef4862>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     ])\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m                 \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                 \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0;31m# Load weights that were specified at layer instantiation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1193\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m         \u001b[0mparam_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(ops)\u001b[0m\n\u001b[1;32m   2200\u001b[0m     \"\"\"\n\u001b[1;32m   2201\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2202\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2203\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2204\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[400001,300]\n\t [[Node: embedding_13/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_13/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_13/embeddings, embedding_13/random_uniform)]]\n\nCaused by op 'embedding_13/embeddings/Assign', defined at:\n  File \"/opt/conda/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/conda/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/conda/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-79-1111ffef4862>\", line 18, in <module>\n    Dense(number_of_classes, activation='softmax')\n  File \"/opt/conda/lib/python3.5/site-packages/keras/models.py\", line 408, in __init__\n    self.add(layer)\n  File \"/opt/conda/lib/python3.5/site-packages/keras/models.py\", line 464, in add\n    layer(x)\n  File \"/opt/conda/lib/python3.5/site-packages/keras/engine/topology.py\", line 576, in __call__\n    self.build(input_shapes[0])\n  File \"/opt/conda/lib/python3.5/site-packages/keras/layers/embeddings.py\", line 101, in build\n    dtype=self.dtype)\n  File \"/opt/conda/lib/python3.5/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/keras/engine/topology.py\", line 400, in add_weight\n    constraint=constraint)\n  File \"/opt/conda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 385, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 346, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 57, in assign\n    use_locking=use_locking, name=name)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[400001,300]\n\t [[Node: embedding_13/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_13/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_13/embeddings, embedding_13/random_uniform)]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, GRU, Dense, Dropout, TimeDistributed,Bidirectional, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "n_fac = 512 \n",
    "bs = 2048\n",
    "n_hidden=256\n",
    "\n",
    "model=Sequential([\n",
    "        Embedding(vocab_size, glove_vec_len, batch_input_shape=(None,max_len),weights=[glove_vecs], trainable=False),\n",
    "        BatchNormalization(),\n",
    "        Bidirectional(GRU(n_hidden,input_shape=(None,n_fac),return_sequences=True)),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        GRU(n_hidden, dropout=0.4, recurrent_dropout=0.1),\n",
    "        Dense(1024, activation='relu'),\n",
    "        Dropout(0.7),\n",
    "        Dense(number_of_classes, activation='softmax')\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Nadam(lr=0.0007)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18600 samples, validate on 979 samples\n",
      "Epoch 1/100\n",
      "18600/18600 [==============================] - 2s 109us/step - loss: 1.0599 - acc: 0.4399 - val_loss: 0.9954 - val_acc: 0.4954\n",
      "Epoch 2/100\n",
      "18600/18600 [==============================] - 1s 35us/step - loss: 0.9761 - acc: 0.5270 - val_loss: 0.9222 - val_acc: 0.6016\n",
      "Epoch 3/100\n",
      "18600/18600 [==============================] - 1s 34us/step - loss: 0.9258 - acc: 0.5667 - val_loss: 0.8351 - val_acc: 0.6425\n",
      "Epoch 4/100\n",
      "18600/18600 [==============================] - 1s 35us/step - loss: 0.8205 - acc: 0.6359 - val_loss: 0.9510 - val_acc: 0.5577\n",
      "Epoch 5/100\n",
      "18600/18600 [==============================] - 1s 34us/step - loss: 0.8835 - acc: 0.6006 - val_loss: 0.7918 - val_acc: 0.6599\n",
      "Epoch 6/100\n",
      "18600/18600 [==============================] - 1s 35us/step - loss: 0.7730 - acc: 0.6670 - val_loss: 0.7670 - val_acc: 0.6670\n",
      "Epoch 7/100\n",
      "18600/18600 [==============================] - 1s 34us/step - loss: 0.7753 - acc: 0.6584 - val_loss: 0.7335 - val_acc: 0.6874\n",
      "Epoch 8/100\n",
      "18600/18600 [==============================] - 1s 35us/step - loss: 0.7797 - acc: 0.6584 - val_loss: 0.7322 - val_acc: 0.6895\n",
      "Epoch 9/100\n",
      "18600/18600 [==============================] - 1s 34us/step - loss: 0.7407 - acc: 0.6810 - val_loss: 0.7543 - val_acc: 0.6670\n",
      "Epoch 10/100\n",
      "18600/18600 [==============================] - 1s 35us/step - loss: 0.7427 - acc: 0.6784 - val_loss: 0.7122 - val_acc: 0.6936\n",
      "Epoch 11/100\n",
      "18600/18600 [==============================] - 1s 35us/step - loss: 0.7262 - acc: 0.6875 - val_loss: 0.7185 - val_acc: 0.7079\n",
      "Epoch 12/100\n",
      "18600/18600 [==============================] - 1s 35us/step - loss: 0.7008 - acc: 0.7051 - val_loss: 0.7293 - val_acc: 0.6823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1f702a9b00>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels, validation_data=(valid_data, valid_labels), batch_size=bs, epochs=100,callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds = model.predict(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 5\n",
    "print(valid_labels[idx])\n",
    "print(valid_preds[idx])\n",
    "print(' '.join([w for w in map(lambda x: glove_words[x], valid_data[idx]) if w != '####']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nevermore = np.zeros((1,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nevermore[0,0] = glove_wordidx['nevermore']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(nevermore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_data[0]\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
